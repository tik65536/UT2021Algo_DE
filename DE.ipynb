{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53f33d3-8a7d-402d-bfc0-566a905faa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7cb97ff-7acb-44ef-b9d6-979b457b79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers)-1\n",
    "        #print(layers)\n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.ReLU\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth-1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        #print(layers[-2])\n",
    "        #print(layers[-1])\n",
    "        \n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "99960ef9-e149-4b11-8df1-c52f218fab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Asssume the dim of Traing and Testing are in shape [N,C,H,W]\n",
    "\n",
    "class DE_MLP():\n",
    "    def __init__(self, outdim=1,maxdepth=70,mindepth=5,minneuron=4,maxneuron=10,bsize=10,epoch=100,initSize=20,maxiter=2000,stopcount=3,\\\n",
    "                 trainingset=None,validationset=None,trainingTarget=None,validateTarget=None):\n",
    "        self.best=[]\n",
    "        self.mean=[]\n",
    "        self.outdim=outdim\n",
    "        self.maxdepth=maxdepth\n",
    "        self.mindepth=mindepth\n",
    "        self.minneuron = minneuron\n",
    "        self.maxneuron = maxneuron\n",
    "        self.bszie = bsize\n",
    "        self.epoch = epoch\n",
    "        self.stopcount = stopcount\n",
    "        self.pplSize = initSize\n",
    "        self.maxiter = maxiter\n",
    "        self.training = trainingset.reshape((trainingset.shape[0],-1))\n",
    "        self.validationSet = validationset.reshape((validationset.shape[0],-1))\n",
    "        self.target=trainingTarget\n",
    "        self.validationTarget = validateTarget\n",
    "        self.MLPlayerlist = []\n",
    "        self.depthlist=np.random.choice(range(self.mindepth,self.maxdepth),self.pplSize,replace=False)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        for i in range(self.pplSize):\n",
    "            depth = self.depthlist[i]\n",
    "            tmp=[]\n",
    "            tmp.append(self.training.shape[1])\n",
    "            for j in range(depth):\n",
    "                tmp.append(np.random.choice(range(self.minneuron,self.maxneuron),1,replace=False)[0])\n",
    "            tmp.append(self.outdim)\n",
    "            tmp=np.array(tmp)\n",
    "            self.MLPlayerlist.append(tmp)\n",
    "        \n",
    "    def fit(config,id_):\n",
    "        dnn = DNN(config)\n",
    "        dnn.layers.to(self.device)\n",
    "        best = float('inf')\n",
    "        stop=0\n",
    "        self.optimizer(dnn.layers.parameters(), lr=0.001)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "        batch = self.trainingset.shape[0]//self.bsize\n",
    "        vbatch = self.validationSet.shape[0]//self.bsize\n",
    "        idxs = [x for x in range(self.trainingset.shape[0])]\n",
    "        vidxs = [x for x in range(self.validationSet.shape[0])]\n",
    "        for e in range(self.epoch):\n",
    "            np.random.shuffle(idxs)\n",
    "            dnn.layers.train()\n",
    "            batchloss=0\n",
    "            for i in range(batch):\n",
    "                idx=idxs[i*self.bsize:i*self.bsize+self.bsize]\n",
    "                self.optimizer.zero_grad()\n",
    "                data = torch.tensor(self.trainingset[idx]).float().to(self.device)\n",
    "                y = torch.tensor(self.target[idx])\n",
    "                yhat = dnn(data)\n",
    "                l = loss(yhat,y)\n",
    "                batchloss+=l.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            dnn.layers.eval()\n",
    "            np.random.shuffle(vidxs)\n",
    "            vloss=0\n",
    "            for i in range(vbatch):\n",
    "                vidx=vidxs[i*self.bsize:i*self.bsize+self.bsize]\n",
    "                vdata = torch.tensor(self.validationSet[vidx]).float().to(self.device)\n",
    "                vy = torch.tensor(self.target[vidx])\n",
    "                vyhat = dnn(vdata)\n",
    "                vl = loss(vyhat,vy)\n",
    "                vloss += vl.item()\n",
    "            if(vloss<best):\n",
    "                vloss=best\n",
    "            else:\n",
    "                stop+=1\n",
    "            print(f'ConfigID: {id_:3d}, Epoch: {e:3d}, Training Loss: {(batchloss/batch):10.8f}, Validation Loss: {(vloss/vbatch):10.8f},\\\n",
    "                    Best: {best:10.8f}, StopCount/Limit: {stop:3d}/{stopcount:3d}')\n",
    "\n",
    "            if(stop>=self.stopcount):\n",
    "                return best,config,id_ \n",
    "\n",
    "    def mutation_1_2_z(self,x1,xs,beta,debug=False):\n",
    "        indim = x1[0]\n",
    "        x1 = x1[1:-1] # remove in/out dim\n",
    "        xs[0] = xs[0][1:-1]\n",
    "        xs[1] = xs[1][1:-1]\n",
    "        if(debug):\n",
    "            print(f'x1 len {x1.shape[0]} xs0 len {xs[0].shape[0]} xs1 len {xs[1].shape[0]}')\n",
    "        #length mutation\n",
    "        minlen = np.min([x1.shape[0],xs[0].shape[0],xs[1].shape[0]])\n",
    "        if(debug):\n",
    "            print(f'minlen {minlen}')          \n",
    "        newminlen = minlen\n",
    "        targetlen=int(np.floor((x1.shape[0]) + beta * (xs[0].shape[0] - xs[1].shape[0])))\n",
    "        if(targetlen==0):\n",
    "            targetlen=x1.shape[0]\n",
    "        elif(targetlen<0):\n",
    "            targetlen=abs(targetlen)\n",
    "        if(targetlen < minlen):\n",
    "            newminlen=targetlen\n",
    "        if(debug):\n",
    "            print(f'New Min Len :{newminlen}, Length Mutation :{targetlen}')\n",
    "        #node mutation\n",
    "        xa = np.zeros((targetlen),dtype=int)\n",
    "        xa = x1[:newminlen] + beta * (xs[0][:newminlen] - xs[1][:newminlen]) # mutate on node with minlen\n",
    "        if(targetlen>minlen):\n",
    "            xaa = np.zeros((targetlen-minlen))\n",
    "            #mutation on the rest\n",
    "            a=None\n",
    "            b=None\n",
    "            c=None\n",
    "            for i in range(targetlen-newminlen):\n",
    "                if(x1.shape[0]<=newminlen+i):\n",
    "                    a=np.random.choice(range(self.mindepth,self.maxdepth),1,replace=False)\n",
    "                if(x1.shape[0]>newminlen+i):\n",
    "                    a=x1[newminlen+i] \n",
    "\n",
    "                if(xs[0].shape[0]<=newminlen+i):\n",
    "                    b=np.random.choice(range(self.mindepth,self.maxdepth),1,replace=False)\n",
    "                elif(xs[0].shape[0]>newminlen+i):\n",
    "                    b=xs[0][newminlen+i]  \n",
    "\n",
    "                if(xs[1].shape[0]<=newminlen+i):\n",
    "                    c=np.random.choice(range(self.mindepth,self.maxdepth),1,replace=False)\n",
    "                elif(xs[1].shape[0]>newminlen+i):\n",
    "                    c=xs[1][newminlen+i]  \n",
    "            \n",
    "                xaa[i]=a + beta * (b - c)\n",
    "            \n",
    "            xa = np.concatenate((xa, xaa), axis=None)\n",
    "            \n",
    "        for i in range(xa.shape[0]):\n",
    "            if(xa[i]>self.maxdepth):\n",
    "                 xa[i]=self.maxdepth\n",
    "            elif(xa[i]<self.mindepth):\n",
    "                  xa[i]=self.mindepth\n",
    "            xa[i] = np.floor(xa[i])\n",
    "        xa = np.concatenate((np.array(indim,dtype=int),np.array(xa,dtype=int),np.array(self.outdim,dtype=int)), axis=None,dtype=int)\n",
    "        return xa\n",
    "    \n",
    "    def crossover1(par):\n",
    "        return np.mean(par,axis=0)\n",
    "    \n",
    "    def run(self,beta=0.5):\n",
    "        current_gen=self.MLPlayerlist\n",
    "        scores = np.zeros((self.pplSize))\n",
    "        #initial Run\n",
    "        #for i in len(self.MLPlayerlist):\n",
    "        #    b,_,_ = self.fit(self.MLPlayerlist[i],self.stopcount,i)\n",
    "        #    scores[i]=b\n",
    "        \n",
    "        #Generation Run\n",
    "        for i in range(self.maxiter):\n",
    "            currentbest = np.min(scores)\n",
    "            currentmean = np.mean(scores)\n",
    "            currentbestidx = np.argmin(scores)\n",
    "            print(f'Run {i:5d} Best: {currentbest}, Mean: {currentmean}, ID:{currentbestidx}, config: {current_gen[currentbestidx]}')\n",
    "        \n",
    "            for j in range(self.pplSize):\n",
    "                parent = current_gen[j]\n",
    "                midxs = np.random.choice(range(0,self.pplSize),3,replace=False)\n",
    "                target = self.MLPlayerlist[midxs[2]]\n",
    "                unitvector = self.mutation_1_2_z(target,self.MLPlayerlist[0:2],0.5)\n",
    "                print(unitvector)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee7795a1-037a-49e3-a4d9-561b93f9ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.zeros((4,3,5,6))\n",
    "val=np.zeros((4,3,5,6))\n",
    "d = DE_MLP(trainingset=train,validationset=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332b483-a48e-46f8-bc94-b4f36144eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8548e-60f7-4624-91f9-0bb2920e799a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
